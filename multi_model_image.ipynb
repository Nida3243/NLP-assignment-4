{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv, set_key\n",
    "from src.encrypt import decrypt_data\n",
    "# from src.encrypt import env_file\n",
    "from src.auth_helpers import get_access_token   \n",
    "from utils.chat_model import AIGatewayLangchainChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret/url.json', 'r') as file:\n",
    "    url_data = json.load(file)\n",
    "AI_GATEWAY_BASE_URL = url_data.get(\"ai_gateway\")\n",
    "issuer_url = url_data.get(\"issuer_url\")\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(\"secret/.env\")\n",
    "\n",
    "# Retrieve the Fernet key and encrypted values\n",
    "loaded_fernet_key = os.getenv('FERNET_KEY').encode()\n",
    "loaded_encrypted_client_id = os.getenv('ENCRYPTED_CLIENT_ID').encode()\n",
    "loaded_encrypted_client_secret = os.getenv('ENCRYPTED_CLIENT_SECRET').encode()\n",
    "\n",
    "# Decrypt the values\n",
    "client_id = decrypt_data(loaded_encrypted_client_id, loaded_fernet_key)\n",
    "client_secret = decrypt_data(loaded_encrypted_client_secret, loaded_fernet_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_access_token(client_id, client_secret, issuer_url)\n",
    "# print(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model with the access token and base URL\n",
    "model = AIGatewayLangchainChatOpenAI(\n",
    "    access_token=access_token, base_url=AI_GATEWAY_BASE_URL, model=\"gpt-4o-2024-05-13\", deere_ai_gateway_registration_id=\"graphics-quality-check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(image_base64, prompt):\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    response = model.invoke([message])\n",
    "    end_time = time.time()\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image_path):\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Ensure the image is in a supported format\n",
    "        if image.format not in [\"PNG\", \"JPEG\", \"GIF\", \"WEBP\"]:\n",
    "            print(f\"Unsupported image format: {image.format}\")\n",
    "            return\n",
    "        else:\n",
    "            # Convert the image to base64\n",
    "            buffered = io.BytesIO()\n",
    "            image.save(buffered, format=image.format)\n",
    "            image_data = buffered.getvalue()\n",
    "            image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "            return image_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r\"C:\\Users\\CDKVF7A\\OneDrive - Deere & Co\\Graphics_Quality_Check\\graphics\\graphics\\25.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bas64 = convert_image(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Extract the following parameters from the provided graphics in json format along with parameter and value:\n",
    "        1. callout\n",
    "        2. dpi\n",
    "        3. Callout Font\n",
    "        4. Image Size '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"callout\": [\"B\", \"C\", \"D\"],\n",
      "  \"dpi\": 72,\n",
      "  \"Callout Font\": \"Arial\",\n",
      "  \"Image Size\": \"225 x 135 pixels\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = invoke_model(im_bas64, prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"check if based on GD&T standards datums are present accurately in the image or not.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
